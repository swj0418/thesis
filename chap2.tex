\chapter{Background}

  Many related methods address the problem of off-axis scattering including classic, machine learning-based, and deep learning approaches. Some classic approaches such as Tissue Harmonic Imaging and Time-Reversal Technique alter the transmit scheme. Others such as Short-Lag Spatial Coherence, Coherence Factor, and Minimum-Variance Beamforming focus on the postprocessing of the receive data; so do machine learning- and deep learning-based methods. In addition, we introduce convolutional neural networks (CNNs) and discuss related CNN-based applications even though they do not directly apply to ultrasound beamforming.

  \section{Classic Acoustic Clutter Suppression Algorithms} % 2-3 pages
    \subsection{Tissue Harmonic Imaging}
      One widely-used approach to suppress cluttered reverberation signals is tissue harmonic imaging (THI). THI circumvents the inherent reverberation in the commonly used fundamental frequency ($f_{c}$) by adopting a higher frequency - the second harmonic frequency ($f_{hc}$). Because reverberation clutter primarily occurs at the fundamental frequency, reflected signals received at a second harmonic frequency are not subject to the same clutter \cite{christopher1997finite, ward1997nonlinear, averkiou1997nonlinear}. As a result, harmonic B-mode images have better quality with higher contrast, improved resolution, and less near-field artifact. However, the tradeoffs of higher frequency are higher attenuation and lower amplitude which cause a loss in axial resolution \cite{muir1980prediction, starritt1986development, humphrey2000nonlinear, cobbold2006foundations, anvari2015primer}. Attenuation is the loss of power (amplitude) as a wave travels through depth. In soft tissue, higher frequency exacerbates attenuation. In addition, the narrowed bandwidth (fewer frequencies) reduces axial resolution \cite{whittingham1999tissue}, which is measures how close two scatters are along the depth dimension. Axial resolution is a function of pulse length as well as transducer frequency.

    \subsection{Time-Reversal Technique}
      Time-reversal is another method for suppressing reverberation clutter. In this method, ultrasound waves are transmitted and received twice. After the initial transmit and receive, the signals are reversed and re-transmitted into the field of view. The re-transmitted signals propagate back and refocus on the original source throughout the same medium, subject to the same reverberation. While clutter noises present differently for each transmit (incoherent), non-clutter signals follow the similar frequency patterns (coherent). This approach sums the original and the re-transmitted signals, amplifying signal and reduces reverberation clutter thanks to the constructive and destructive interference of waves depending on coherence. The limitation for this approach is its requirement for a point-like source (e.g., a kidney stone) in the medium as the focal region is difficult to determine \cite{dei_thesis, fink1992time}.


    \subsection{Short-Lag Spatial Coherence}
      Short-lag spatial coherence (SLSC) is a beamforming technique that takes advantage of the spatial similarity among the response waves across the aperture \cite{slsc}. Instead of summing across the channels as is the case in delay-and-sum (DAS) beamforming, SLSC measures - for each beam - the average correlation between all pairs of channels separated by \textit{l} ("lag") elements, for a given set of lags. The rationale behind this approach is that adjacent channel signals (short lags) are coherent (similar) spatially, but noises are incoherent. Coherence is a form of correlation or covariance between waves. Coherent waves have the same shape but are separated by a time delay. Weighted multiplication of waves would amplify the coherent components (the desired signals) and suppress the incoherent ones (the noises). As a result, the beaformed images show higher contrast, improved contrast-to-noise ratios, and better image texture \cite{dahl2017coherence}. The tradeoffs for these improvements include more computational complexity from additional matrix-based correlation derivation and loss in image resolution from only utilizing partial aperture information \cite{lediju2015resolution}. Moreover, the values in the image matrix are correlation measures instead of dB. Therefore, SLSC images are not directly comparable to B-mode images.

    \subsection{Coherence Factor}
      Coherence factor (CF) is a post-processing technique that computes a weight for each beam and each depth and applies these weights to the delay-and-sum (DAS) beamformed RF data \cite{mallart1994adaptive, hollman1999coherence}. Mathematically, the CF is the ratio of the sum of coherent signals over all signals in each beam. Similar to SLSC, CF takes advantage of the high-coherence property of non-clutter signals to suppress cluttered signals. Compared with SLSC, this method improves image contrast while avoiding introducting of high computational complexity \cite{dei_thesis}. However, CF images tend to have a poor dynamic range because it suppresses signals in hypoechoic (mostly black) regions, making them look anechoic (completely black). It also destroys the speckle pattern and thus reduces the contrast-to-noise ratio (CNR) in images.

    \subsection{Minimum-Variance Beamforming}
      Minimum variance (MV) beamforming is an approach to suppress off-axis scattering. It does so by minimizing the power (the zero-mean variance) of off-axis regions, while preserving the power of the target region (a point location) \cite{synnevag2007adaptive, holfort2009broadband}. MV has proven effective in improving contrast in phantom targets. The drawback of MV is its sensitivity to the dB variation from inside the focal region. In addition, the image quality improvements do not translate to \textit{in vivo} images. %TODO find citatations for pros and cons.

  \section{Machine Learning-Based Acoustic Clutter Suppression Algorithms}
    \subsection{ADMIRE}

      Aperture Domain Model Image Reconstruction (ADMIRE) is a model-based approach to suppress both off-axis scattering and reverberation clutter. It operates on frequency-domain channel data, decomposes the cluttered signal, selects the scatterer in the region of interest (ROI), and reconstructs the decluttered signal. It then uses regression to determine the coefficient for regularizing each component signal. ADMIRE proves highly effective in suppressing both off-axis scattering and reverberation clutter. However, the computational complexity inherent in this approach precludes real-time applications until further optimization can increase the frame rate \cite{dei_thesis, admire2015}.

    \subsection{Regularized Inverse}
      Another machine learning-based approach is regularized inverse, or least squares (LS) beamforming. Given the steering angles - the directions of transducer elements in a beam to form a curved wavefront for focused imaging - \textit{a priori}, this approach modeled each lateral scanline in the DAS beamformed RF data as a function of the scatterer's peak signal (desired), the given steering matrix, and a Gaussian error term. Stacking the per-depth least squares solutions to the model, the LS approach produces images with improved contrast-to-noise ratios (CNR) \cite{szasz_regularized_inverse}. % TODO: cons?

  \section{Deep Learning-Based Acoustic Clutter Suppression Algorithm} % 5-6 pages.
    \subsection{Introduction to Neural Networks}
      Neural networks are machine learning models that learn by backpropagating loss. They are theoretically able to learn a broad set of complex functions by using nonlinear activations \cite{rumelhart1985learning}. Convolutional Neural Networks (CNNs) are special neural networks that take advantage of localized parameter sharing, requiring fewer parameters and thus having a reduced risk of overfitting. CNNs have seen widespread applications in Computer Vision, Natural Language Processing, and Medical Imaging alike.

      LeNet is the first influential CNN architecture for classifying images. It consists of two convolutional layers followed by two fully-connected ones. Each convolutional layer is followed by a pooling layer for down-sampling. This small architecture was successfully used to recognize handwritten digits \cite{lenet}. Another early architecture is AlexNet with 5 convolutional layers followed by fully-connected ones \cite{krizhevsky2012imagenet}, which became the first neural-network winner for the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) in 2012.

    \subsection{Random Hyperparameter Search and Neural Architecture Search}
      Training neural networks involves selecting training and model hyperparameters such as learning rate, dropout rate, and the width of fully-connected layers. Recent studies show that random search is more effective than grid search in finding the optimal neural network \cite{bergstra2012random}. Furthermore, as there are no established models for ultrasound beamforming, a random search for hyperparameters in model arhitecture, such as the kernel dimensions, the number of kernels, and the padding/stride dimensions for a convolutional layer may be necessary.

      A related technique for model selection is neural architecture search (NAS), which uses search heuristics such as reinforcement learning \cite{zoph2016neural, pham2018efficient} or evolution \cite{real2017large} to choose a model architecture that minimizes a separate validation loss. A common strategy is having a controller - itself a recurrent neural network model - select and evaluate types of layers in a child model (the optimal model). However, at the time of writing, popular automated machine learning (AutoML) frameworks such as Auto-Keras \cite{jin2019auto} and Neural Network Intelligence (NNI) do not support automated search of convolutional neural networks for regression tasks. To address this problem, I implement a hybrid search that manually defines the types and ordering of layers, only to vary their sizes and the number of layers. This approach is discussed in detail in the Methods section.

    \subsection{CNN Architectures}
      Most well-known CNN architectures have fully-connected layers after convolutional ones. However, it is not always clear that full connections are necessary as they flatten the spatial features detected by the convolutional layers. There are two notable architectures that avoids using fully-connected layers: the Fully Convolutional Network (FCN) \cite{long2015fcn} and U-Net \cite{ronneberger2015unet}. Both were proposed to solve the problem of semantic segmentation or pixel-wise image classification, while U-Net focuses on biomedical images. Although they differ in architecture, both feature bottlenecks/encoder-decoders and upsampling layers in order to bring the shrunk convolutional outputs back to the size of the input.

      The bottleneck layer is an intermediate layer that reduces the size of data coming from its previous layer. Bottleneck layers are used to obtain a (nonlinear) representation of the input with reduced dimensionality, i.e., performing dimension reduction. An example bottleneck layer is an autoencoder, which is used to reduce the previous output and is in turn used to generate a larger encoding that approximates the original input (hence "auto") \cite{ballard1987modular}. For example, the GoogLeNet architecture that won the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC2014) features 1 by 1 convolutional blocks (termed "network-in-networks" or NiNs) that reduce the number of features before the computationally expensive parallel blocks. \cite{szegedy2015going}. This bottleneck-upsampling approach is a promising network design element that could also be applied to regression tasks because it enables output sizes to match the input.

    \subsection{Convolutional Neural Networks for General Regression}
      One example CNN solution to a regression task is image orientation prediction. Fischer et al. proposed an approach to train a modified AlexNet to output the orientation of an image. The input is an image while the output is either a single value in degrees or two values - the sine y and cosine x of an input image. They use significant amount of data augmentation where they generate new training examples by rotating existing ones. The results suggest that predicting a single rotation value is difficult. They found that a single CNN performed poorly compared with a hybrid classification-regression method that performed better than non-neural network approaches, albeit with a nontrivial mean absolute error of $21\degree$ for rotations in the range of $[-180\degree, 180\degree]$ \cite{fischer2015image}. Although the problem addressed in this study is different from mine in terms of the output resolution, both tasks have an implicit classification component. For their hybrid approach, a rough orthogonal rotation is classified at first before a finer rotation is finally predicted. For the aperture-domain denoising problem that I consider, a neural network is trained to recognize three signal modes: accept, reject, and mixed. It must then extract the signal component. My problem definition is discussed in the Methods section.

    \subsection{Multi-Layer Perceptrons for Suppressing Off-Axis Scattering}
      Recently, Luchies and Byram proposed a neural-network approach to suppress off-axis scattering \cite{luchies_tmi_2018, training_improvements}. They trained multi-layer perceptrons (MLPs) that operated in the short-time Fourier transform (STFT) or the frequency domain to suppress the off-axis signals based on simulated point targets. These beamformers are convolutional in nature insofar as the networks, including their weights, are reused through depth; however, fully-connected layers are used to span the aperture dimension. This method proved effective in improving contrast while preserving speckle patterns. This work motivates further exploration of CNNs on the same STFT-domain data, as there may be spatial features in the frequency domain that could be more effectively learned by CNNs, such as aperture shapes. In addition, training in the STFT domain helps avoid having to train for experimental parameters such as different pulse shapes and depth dependent attenuation. % TODO: explain why avoids different pulse shapes and depth dependent attenuation

    \subsection{Convolutional Neural Networks for Beamforming}
      There are two notable related CNN-based approaches for reducing off-axis scattering, learning ultrasound reconstruction, and speckle reduction. For example, Yoon et al. proposed a method that effectively interpolates missing sub-sampled RF data in 3D ultrasound \cite{yoon2018efficient}.

      Hyun et al. showed that fully-convolutional neural networks (FCNs) have the potential to learn a speckle-reducing beamformer which also suppresses off-axis scattering. Their learning tasks is to beamform a B-mode image from raw RF data. Their networks used between 2 and 16 convolutional layers with same padding in order to preserve the input dimensionality throughout the network. Notably, they explored different loss functions including L1, L2, SSIM, and MS-SSIM losses. They were able to show SNR improvements in both phantom and \textit{in vivo} targets. However, the images did not indicate clear CNR improvements for all targets \cite{hyun2019beamforming}.
